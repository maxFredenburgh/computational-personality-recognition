{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predicting Author Personality Traits from Social Media Posts</h1>\n",
    "<h3>Maxwell Fredenburgh</h3>\n",
    "\n",
    "<h2>Part 1: Introduction</h2>\n",
    "\n",
    "<p>In this Notebook, I will walk through the process of using Machine Learning and Natural Language Processing in order to predict \n",
    "the Big-5 personality traits of a user based on their Social Media posts and other Social Media data.</p>\n",
    "\n",
    "<p>The Big-5 perosnality model is the most popular measure of one's personality used by psychologists. This model describes an individual's personality through 5 key traits: Conscientiousness, Agreeableness, Neuroticism, Openness, and Extraversion</p>\n",
    "\n",
    "<p><strong>Conscientiousness</strong> (messy vs. organized): characterized by one’s organization and setting of goals.</p>\n",
    "<p><strong>Agreeableness</strong> (uncooperative vs. cooperative): characterized by one’s cooperativeness with others.</p>\n",
    "<p><strong>Neuroticism</strong> (emotional instability vs. emotional stability): characterized by one’s emotional stability.</p>\n",
    "<p><strong>Openness</strong> (unimaginative vs. insightful): characterized by one’sinsightfulness, imagination, and ability to consider abstract ideas.</p>\n",
    "<p><strong>Extraversion</strong> (shy vs. sociable): characterized by one’s sociability with others.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: The Data</h2>\n",
    "\n",
    "<h3>A. The default dataset</h3>\n",
    "<p>A sample of the myPersonality dataset collected by Michal Kosinski and David Stillwell from the University of Cambridge.</p> \n",
    "<p>Celli, F., Pianesi, F., Stillwell, D., & Kosinski, M. (2013). Workshop on\n",
    "Computational Personality Recognition: Shared Task. AAAI Workshop - Technical\n",
    "Report . Association for the Advancement of Artificial Intelligence.</p>\n",
    "<a href=\"https://www.researchgate.net/profile/Fabio_Celli/publication/258045642_Workshop_on_Computational_Personality_Recognition_Shared_Task/links/00b49526b90298373b000000/Workshop-on-Computational-Personality-Recognition-Shared-Task.pdf\">https://www.researchgate.net/profile/Fabio_Celli/publication/258045642_Workshop_on_Computational_Personality_Recognition_Shared_Task/links/00b49526b90298373b000000/Workshop-on-Computational-Personality-Recognition-Shared-Task.pdf</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/19/09 03:21 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/02/09 08:41 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/15/09 01:15 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/22/09 04:48 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/20/09 02:31 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            #AUTHID  \\\n",
       "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65   3.0  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65   3.0  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65   3.0  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65   3.0  3.15  3.25   \n",
       "4                                        is home. <3  2.65   3.0  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU cAGR cCON cOPN               DATE  NETWORKSIZE  BETWEENNESS  \\\n",
       "0   4.4    n    y    n    n    y  06/19/09 03:21 PM        180.0      14861.6   \n",
       "1   4.4    n    y    n    n    y  07/02/09 08:41 AM        180.0      14861.6   \n",
       "2   4.4    n    y    n    n    y  06/15/09 01:15 PM        180.0      14861.6   \n",
       "3   4.4    n    y    n    n    y  06/22/09 04:48 AM        180.0      14861.6   \n",
       "4   4.4    n    y    n    n    y  07/20/09 02:31 AM        180.0      14861.6   \n",
       "\n",
       "   NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \n",
       "0         93.29     0.03    15661.0        0.49           0.1  \n",
       "1         93.29     0.03    15661.0        0.49           0.1  \n",
       "2         93.29     0.03    15661.0        0.49           0.1  \n",
       "3         93.29     0.03    15661.0        0.49           0.1  \n",
       "4         93.29     0.03    15661.0        0.49           0.1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "df = pd.read_csv(\"data/mypersonality_final.csv\", encoding=\"ISO-8859-1\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 9917\n",
      "Number of columns: 20\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows: '+str(df.shape[0]))\n",
    "print('Number of columns: '+str(df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. Data cleaning</h3>\n",
    "<p>Changing y/n values to binary 1/0 and remove rows with N/A values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              STATUS  NETWORKSIZE  \\\n",
       "0                        likes the sound of thunder.        180.0   \n",
       "1  is so sleepy it's not even funny that's she ca...        180.0   \n",
       "2  is sore and wants the knot of muscles at the b...        180.0   \n",
       "3         likes how the day sounds in this new song.        180.0   \n",
       "4                                        is home. <3        180.0   \n",
       "\n",
       "   BETWEENNESS  NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \\\n",
       "0      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "1      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "2      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "3      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "4      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "\n",
       "   cEXT  cNEU  cAGR  cCON  cOPN  \n",
       "0     0     1     0     0     1  \n",
       "1     0     1     0     0     1  \n",
       "2     0     1     0     0     1  \n",
       "3     0     1     0     0     1  \n",
       "4     0     1     0     0     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myp = df[['STATUS','NETWORKSIZE','BETWEENNESS','NBETWEENNESS','DENSITY','BROKERAGE','NBROKERAGE','TRANSITIVITY','cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "myp['cEXT'] = myp['cEXT'].map({'y': 1, 'n': 0})\n",
    "myp['cNEU'] = myp['cNEU'].map({'y': 1, 'n': 0})\n",
    "myp['cAGR'] = myp['cAGR'].map({'y': 1, 'n': 0})\n",
    "myp['cCON'] = myp['cCON'].map({'y': 1, 'n': 0})\n",
    "myp['cOPN'] = myp['cOPN'].map({'y': 1, 'n': 0})\n",
    "\n",
    "#drop rows with NaN values\n",
    "included_features = ['NETWORKSIZE','BETWEENNESS','NBETWEENNESS','DENSITY','BROKERAGE','NBROKERAGE','TRANSITIVITY']\n",
    "for f in included_features:\n",
    "    myp = myp[myp[f].notna()]\n",
    "    \n",
    "bigdata = myp\n",
    "bigdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 9916\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows: '+str(bigdata.shape[0]))\n",
    "print('Number of columns: '+str(bigdata.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Baseline Analysis</h2>\n",
    "<p>Through data exploration, we can compute the number of positive and negative classifications\n",
    "for each class (CANOE) and therefore the prior probabilities of each class being predicted.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21d25ddc278>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "value_counts = pd.DataFrame({'Trait':['cCON', 'cAGR', 'cNEU', 'cOPN', 'cEXT'],\n",
    "                   'N count':[bigdata[\"cCON\"].value_counts()[0],bigdata[\"cAGR\"].value_counts()[0],bigdata[\"cNEU\"].value_counts()[0],bigdata[\"cOPN\"].value_counts()[0],bigdata[\"cEXT\"].value_counts()[0]],\n",
    "                   'Y count': [bigdata[\"cCON\"].value_counts()[1],bigdata[\"cAGR\"].value_counts()[1],bigdata[\"cNEU\"].value_counts()[1],bigdata[\"cOPN\"].value_counts()[1],bigdata[\"cEXT\"].value_counts()[1]]})\n",
    "value_counts.plot(x=\"Trait\", y=[\"N count\", \"Y count\"], kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can assume the accuracy of a hypothetical untrained classification model in\n",
    "predicting the classification of each personality trait. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trait</th>\n",
       "      <th>N count</th>\n",
       "      <th>Y count</th>\n",
       "      <th>prior probability N</th>\n",
       "      <th>prior probability Y</th>\n",
       "      <th>Hypothetical Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cCON</td>\n",
       "      <td>5361</td>\n",
       "      <td>4555</td>\n",
       "      <td>54.06</td>\n",
       "      <td>45.94</td>\n",
       "      <td>54.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cAGR</td>\n",
       "      <td>4649</td>\n",
       "      <td>5267</td>\n",
       "      <td>46.88</td>\n",
       "      <td>53.12</td>\n",
       "      <td>53.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cNEU</td>\n",
       "      <td>6199</td>\n",
       "      <td>3717</td>\n",
       "      <td>62.52</td>\n",
       "      <td>37.48</td>\n",
       "      <td>62.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cOPN</td>\n",
       "      <td>2547</td>\n",
       "      <td>7369</td>\n",
       "      <td>25.69</td>\n",
       "      <td>74.31</td>\n",
       "      <td>74.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cEXT</td>\n",
       "      <td>5707</td>\n",
       "      <td>4209</td>\n",
       "      <td>57.55</td>\n",
       "      <td>42.45</td>\n",
       "      <td>57.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trait  N count  Y count  prior probability N  prior probability Y  \\\n",
       "0  cCON     5361     4555                54.06                45.94   \n",
       "1  cAGR     4649     5267                46.88                53.12   \n",
       "2  cNEU     6199     3717                62.52                37.48   \n",
       "3  cOPN     2547     7369                25.69                74.31   \n",
       "4  cEXT     5707     4209                57.55                42.45   \n",
       "\n",
       "   Hypothetical Accuracy %  \n",
       "0                    54.06  \n",
       "1                    53.12  \n",
       "2                    62.52  \n",
       "3                    74.31  \n",
       "4                    57.55  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in value_counts.iterrows():\n",
    "    sum = row['N count']+row['Y count']\n",
    "    ppN = round((row['N count']/sum)*100, 2)\n",
    "    ppY = round((row['Y count']/sum)*100, 2)\n",
    "    hyp_acc = max(ppN, ppY)\n",
    "    value_counts.loc[index, 'prior probability N'] = ppN\n",
    "    value_counts.loc[index, 'prior probability Y'] = ppY\n",
    "    value_counts.loc[index, 'Hypothetical Accuracy %'] = hyp_acc\n",
    "value_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For example, if we were to create a model\n",
    "that only classifies a status as being positive in trait Openness, then we can expect the model\n",
    "to have an accuracy score of 74.31%. Our goal will be to have an increase in classification accuracy compared to these hypothetical accuracies.</p>\n",
    "<p>If we see an increase in classification accuracy with the models trained on linguisitc features, then we can conclude that personality traits do express different linguistic cues within text, and that the identification of these linguistic cues can aid in the classification of the Big-5 personality traits of the author</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 4: Natural Language Processing and Feature Creation</h2>\n",
    "<p>Pennbaker and King (1999) found many correlations between the Big-5 personality traits of University of Texas students and the linguisitc cues observed in their essays. A summary of these correlations can be found in the table below.</p>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Big-5 Trait</th>\n",
    "    <th>Associated Linguistic Cues</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Conscientiousness</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>Avoidance of negations</li>\n",
    "            <li>Avoidance of negative emotion words</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Agreeableness</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>More frequent use of positive emotion words</li>\n",
    "            <li>Avoidance of negative emotion words</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neuroticism</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>More frequent use of negative emotion words</li>\n",
    "            <li>Less frequent use of positive emotion words</li>\n",
    "            <li>More frequent use of first-person singular pronouns</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Openness</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>Avoidance of first-person singular pronouns</li>\n",
    "            <li>Avoidance of present-tense forms</li>\n",
    "            <li>Tendency to use longer words</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Extraversion</td>\n",
    "    <td>\n",
    "        <ul>\n",
    "            <li>More frequent use of positive words</li>\n",
    "            <li>More frequent use of pronouns, verbs, adverbs, and interjections</li>\n",
    "        </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p>Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use as an individual\n",
    "difference . Journal of Personality and Social Psychology, 77, 1296–1312.</p>\n",
    "<a href=\"https://www.researchgate.net/publication/12688664_Linguistic_styles_Language_use_as_an_individual_difference\">https://www.researchgate.net/publication/12688664_Linguistic_styles_Language_use_as_an_individual_difference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Based on the findings of Pennbaker & King (1999), we can use NLP techniques to identify relevant linguisitc feautres within statuses:</p>\n",
    "<p><strong>Step 1.</strong> Use ScikitLearn’s (SKLearn) CountVectorizer to convert the statuses to a\n",
    "matrix of token counts.</p>\n",
    "<p><strong>Step 2.</strong> Use Natural Language Toolkit’s (NLTK) word_tokenizer to remove\n",
    "non-alphanumeric tokens and stopwords from each status.</p>\n",
    "<p><strong>Step 3. </strong>Count the number of tokens and the average length of tokens in each status.</p>\n",
    "<p><strong>Step 4. </strong>Use AFINN Sentiment Analysis to determine the frequency of positive emotion\n",
    "words, frequency of negative emotion words, and overall sentiment of status.</p>\n",
    "<p><strong>Step 5.</strong> Use NLTK’s Part-of-Speech (POS) tagger to determine the frequencies of\n",
    "grammatical categories (eg. noun, verb, adjective, etc) and numbers (plural,\n",
    "singular). This will create a frequency feature for each POS-tag (eg. NN,\n",
    "VB, JJ, etc).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import NLP Libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "#nltk.download('stopwords')\n",
    "# Import the stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from afinn import Afinn\n",
    "af = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "for status in bigdata[\"STATUS\"]:\n",
    "    tokens = word_tokenize(status.lower())\n",
    "    tok_alpha = [t for t in tokens if re.match(\"^[a-zA-Z]+$\", t)]\n",
    "    posTok = nltk.pos_tag(tok_alpha)\n",
    "    for tokenPOS in posTok:\n",
    "        token = tokenPOS[0]\n",
    "        pos = tokenPOS[1]\n",
    "        if not pos in features:\n",
    "            features[pos] = []\n",
    "\n",
    "features[\"numTokens\"] = []\n",
    "features[\"avgTokenLen\"] = []\n",
    "features[\"sentimentScore\"] = []\n",
    "features[\"posEmo\"] = []\n",
    "features[\"negEmo\"] = []\n",
    "features[\"neuEmo\"] = []\n",
    "\n",
    "for status in bigdata[\"STATUS\"]:\n",
    "    tokens = word_tokenize(status.lower())\n",
    "    tok_alpha = [t for t in tokens if re.match(\"^[a-zA-Z]+$\", t)]\n",
    "    posTok = nltk.pos_tag(tok_alpha)\n",
    "    numTokens = len(tok_alpha)\n",
    "    totalCharLen = 0\n",
    "    posEmo = 0\n",
    "    negEmo = 0\n",
    "    neuEmo = 0\n",
    "    \n",
    "    statusFeatures = {}\n",
    "    \n",
    "    for tokenPOS in posTok:\n",
    "        token = tokenPOS[0]\n",
    "        pos = tokenPOS[1]\n",
    "        totalCharLen+=len(token)\n",
    "        emo = af.score(token)\n",
    "        if emo==0:\n",
    "            neuEmo+=1\n",
    "        elif emo>0:\n",
    "            posEmo+=1\n",
    "        else:\n",
    "            negEmo+=1\n",
    "        \n",
    "        if pos in statusFeatures:\n",
    "            statusFeatures[pos] += (1/numTokens)\n",
    "            #statusFeatures[pos] += (1)\n",
    "        else:\n",
    "            statusFeatures[pos] = (1/numTokens)\n",
    "            #statusFeatures[pos] += (1)\n",
    "            \n",
    "    if numTokens != 0:\n",
    "        statusFeatures[\"numTokens\"] = numTokens\n",
    "        statusFeatures[\"avgTokenLen\"] = totalCharLen/numTokens\n",
    "        statusFeatures[\"sentimentScore\"] = af.score(status)\n",
    "        statusFeatures[\"posEmo\"] = posEmo/numTokens\n",
    "        statusFeatures[\"negEmo\"] = negEmo/numTokens\n",
    "        statusFeatures[\"neuEmo\"] = neuEmo/numTokens\n",
    "    else:\n",
    "        statusFeatures[\"numTokens\"] = 0\n",
    "        statusFeatures[\"avgTokenLen\"] = 0\n",
    "        statusFeatures[\"sentimentScore\"] = 0\n",
    "    \n",
    "    for key in features:\n",
    "        if key in statusFeatures:\n",
    "            features[key].append(statusFeatures[key])\n",
    "        else:\n",
    "            features[key].append(0)\n",
    "\n",
    "# Normalize sentimentScore to no negative values\n",
    "min_score = min(features[\"sentimentScore\"])          \n",
    "features[\"sentimentScore\"] = [t + (-1*min_score) for t in features[\"sentimentScore\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add the features and values to dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>NNP</th>\n",
       "      <th>RBS</th>\n",
       "      <th>WP$</th>\n",
       "      <th>POS</th>\n",
       "      <th>numTokens</th>\n",
       "      <th>avgTokenLen</th>\n",
       "      <th>sentimentScore</th>\n",
       "      <th>posEmo</th>\n",
       "      <th>negEmo</th>\n",
       "      <th>neuEmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.560000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              STATUS  NETWORKSIZE  \\\n",
       "0                        likes the sound of thunder.        180.0   \n",
       "1  is so sleepy it's not even funny that's she ca...        180.0   \n",
       "2  is sore and wants the knot of muscles at the b...        180.0   \n",
       "3         likes how the day sounds in this new song.        180.0   \n",
       "4                                        is home. <3        180.0   \n",
       "\n",
       "   BETWEENNESS  NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \\\n",
       "0      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "1      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "2      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "3      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "4      14861.6         93.29     0.03    15661.0        0.49           0.1   \n",
       "\n",
       "   cEXT  cNEU  ...  NNP  RBS  WP$  POS  numTokens  avgTokenLen  \\\n",
       "0     0     1  ...  0.0  0.0  0.0  0.0        5.0     4.400000   \n",
       "1     0     1  ...  0.0  0.0  0.0  0.0       13.0     3.307692   \n",
       "2     0     1  ...  0.0  0.0  0.0  0.0       25.0     3.560000   \n",
       "3     0     1  ...  0.0  0.0  0.0  0.0        9.0     3.666667   \n",
       "4     0     1  ...  0.0  0.0  0.0  0.0        2.0     3.000000   \n",
       "\n",
       "   sentimentScore    posEmo  negEmo    neuEmo  \n",
       "0            38.0  0.200000    0.00  0.800000  \n",
       "1            40.0  0.076923    0.00  0.923077  \n",
       "2            35.0  0.000000    0.12  0.880000  \n",
       "3            38.0  0.111111    0.00  0.888889  \n",
       "4            39.0  0.000000    0.00  1.000000  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in features:\n",
    "    bigdata[key] = np.asarray(list(map(float, features[key])))\n",
    "bigdata = bigdata[bigdata.numTokens != 0]\n",
    "bigdata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Create 3 different feature sets for training classification models: </p>\n",
    "<p><strong>Linguistic Cues (LC): </strong>CountVectorizer matrix of token counts, number of tokens, average token\n",
    "length, positive emotion word frequency, negative emotion word\n",
    "frequency, sentiment score of status, POS-tag frequency.</p>\n",
    "<p><strong>Social Network Metadata (SNM): </strong>Network size, betweenness, density, brokerage, and\n",
    "transitivity.</p>\n",
    "<p><strong>All (A): </strong>All LC features plus all SNM features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Sets\n",
      "linguistic features: ['VBZ', 'DT', 'NN', 'IN', 'RB', 'JJ', 'PRP', 'VBP', 'MD', 'VB', 'TO', 'RBR', 'CC', 'NNS', 'PRP$', 'WRB', 'VBD', 'VBG', 'VBN', 'CD', 'WP', 'RP', 'WDT', 'JJR', 'JJS', 'PDT', 'EX', 'FW', 'UH', 'NNP', 'RBS', 'WP$', 'POS', 'numTokens', 'avgTokenLen', 'sentimentScore', 'posEmo', 'negEmo', 'neuEmo']\n",
      "social network features: ['NETWORKSIZE', 'BETWEENNESS', 'NBETWEENNESS', 'DENSITY', 'BROKERAGE', 'NBROKERAGE', 'TRANSITIVITY']\n",
      "all features: ['VBZ', 'DT', 'NN', 'IN', 'RB', 'JJ', 'PRP', 'VBP', 'MD', 'VB', 'TO', 'RBR', 'CC', 'NNS', 'PRP$', 'WRB', 'VBD', 'VBG', 'VBN', 'CD', 'WP', 'RP', 'WDT', 'JJR', 'JJS', 'PDT', 'EX', 'FW', 'UH', 'NNP', 'RBS', 'WP$', 'POS', 'numTokens', 'avgTokenLen', 'sentimentScore', 'posEmo', 'negEmo', 'neuEmo', 'NETWORKSIZE', 'BETWEENNESS', 'NBETWEENNESS', 'DENSITY', 'BROKERAGE', 'NBROKERAGE', 'TRANSITIVITY']\n"
     ]
    }
   ],
   "source": [
    "#Defining different feature sets for training\n",
    "lingustic_features = list(features.keys())\n",
    "all_features = list(features.keys())\n",
    "social_network_metadata = ['NETWORKSIZE','BETWEENNESS','NBETWEENNESS','DENSITY','BROKERAGE','NBROKERAGE','TRANSITIVITY']\n",
    "all_features.extend(social_network_metadata)\n",
    "print(\"Feature Sets\")\n",
    "print(\"linguistic features: \"+ str(lingustic_features))\n",
    "print(\"social network features: \"+ str(social_network_metadata))\n",
    "print(\"all features: \"+ str(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 5: Creation of Classification Models</h2>\n",
    "<p>We train and test the 3 different feature sets with 4 different classification models: Naive Bayes, Logistic Regression, Multi-Layered Perceptron, and Gradient Boost</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y):\n",
    "    \n",
    "    train, test, train_tags, test_tags = train_test_split(X, y,test_size=0.145,random_state=10)\n",
    "    \n",
    "    #Naive Bayes\n",
    "    clf_nb = MultinomialNB().fit(train, train_tags)\n",
    "    print(\"NB: train accuracy - \" + str(round(clf_nb.score(train,train_tags)*100,2))+\"%\", \n",
    "          \"test accuracy - \" + str(round(clf_nb.score(test,test_tags)*100,2))+\"%\")\n",
    "    \n",
    "    #Logistic Regression\n",
    "    clf_lr = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\", max_iter=28000, random_state=0)\n",
    "    clf_lr.fit(train, train_tags)\n",
    "    print(\"LR: train accuracy - \" + str(round(clf_lr.score(train,train_tags)*100,2))+\"%\", \n",
    "          \"test accuracy - \" + str(round(clf_lr.score(test,test_tags)*100,2))+\"%\")\n",
    "    \n",
    "    #MLP\n",
    "    clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(24, 12), random_state=0, max_iter=10000, learning_rate_init=0.01, warm_start=True)\n",
    "    clf_mlp.fit(train, train_tags)\n",
    "    print(\"MLP:train accuracy - \" + str(round(clf_mlp.score(train,train_tags)*100,2))+\"%\", \n",
    "          \"test accuracy - \" + str(round(clf_mlp.score(test,test_tags)*100,2))+\"%\")\n",
    "    \n",
    "    #Boosting\n",
    "    clf_b = GradientBoostingClassifier(random_state=0)\n",
    "    clf_b.fit(train, train_tags)\n",
    "    print(\"GB: train accuracy - \" + str(round(clf_b.score(train,train_tags)*100,2))+\"%\", \n",
    "          \"test accuracy - \" + str(round(clf_b.score(test,test_tags)*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 6: Training and Testing Different Feature Sets</h2>\n",
    "<p>Train each model in classifying each personality trait for each feature set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "traits = ['cCON','cAGR','cNEU','cOPN','cEXT']\n",
    "\n",
    "def train_test_label(feature_set_label,feature_set, labels):\n",
    "    print(\"----------\"+feature_set_label+\"----------\")\n",
    "    X = sp.sparse.hstack((count_vect.fit_transform(bigdata['STATUS']),\n",
    "                        bigdata[feature_set]),\n",
    "                        format='csr')\n",
    "    for label in labels:\n",
    "        print(\"-----\"+label+\"-----\")\n",
    "        y = bigdata[[label]].values.ravel()\n",
    "        train_test(X,y)  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Linguisitc Cues Feature Set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------lingustic features----------\n",
      "-----cCON-----\n",
      "NB: train accuracy - 86.28% test accuracy - 61.12%\n",
      "LR: train accuracy - 93.44% test accuracy - 60.77%\n",
      "MLP:train accuracy - 94.52% test accuracy - 59.58%\n",
      "GB: train accuracy - 64.38% test accuracy - 57.06%\n",
      "-----cAGR-----\n",
      "NB: train accuracy - 84.82% test accuracy - 60.98%\n",
      "LR: train accuracy - 93.44% test accuracy - 59.16%\n",
      "MLP:train accuracy - 85.27% test accuracy - 57.27%\n",
      "GB: train accuracy - 63.67% test accuracy - 55.52%\n",
      "-----cNEU-----\n",
      "NB: train accuracy - 81.68% test accuracy - 64.34%\n",
      "LR: train accuracy - 93.4% test accuracy - 62.24%\n",
      "MLP:train accuracy - 71.53% test accuracy - 62.38%\n",
      "GB: train accuracy - 66.54% test accuracy - 63.01%\n",
      "-----cOPN-----\n",
      "NB: train accuracy - 82.38% test accuracy - 76.78%\n",
      "LR: train accuracy - 93.13% test accuracy - 75.59%\n",
      "MLP:train accuracy - 77.12% test accuracy - 74.9%\n",
      "GB: train accuracy - 75.79% test accuracy - 76.71%\n",
      "-----cEXT-----\n",
      "NB: train accuracy - 84.05% test accuracy - 61.54%\n",
      "LR: train accuracy - 93.22% test accuracy - 62.03%\n",
      "MLP:train accuracy - 98.67% test accuracy - 60.14%\n",
      "GB: train accuracy - 64.5% test accuracy - 60.28%\n"
     ]
    }
   ],
   "source": [
    "train_test_label('lingustic features',lingustic_features, traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Best Results for Linguisitc Cues Feature Set compared to Hypothetical Accuracies:</p>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Big-5 Trait</th>\n",
    "    <th>Best Accuracy % (NB)</th>\n",
    "    <th>Hypothetical Accuracy %</th>\n",
    "    <th>Difference %</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Conscientiousness</td>\n",
    "    <td>61.12</td>\n",
    "    <td>54.06</td>\n",
    "    <td>+7.06</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Agreeableness</td>\n",
    "    <td>60.98</td>\n",
    "    <td>53.12</td>\n",
    "    <td>+7.86</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neuroticism</td>\n",
    "    <td>76.78</td>\n",
    "    <td>62.52</td>\n",
    "    <td>+14.26</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Openness</td>\n",
    "    <td>76.78</td>\n",
    "    <td>74.31</td>\n",
    "    <td>+2.47</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Extraversion</td>\n",
    "    <td>61.54</td>\n",
    "    <td>57.55</td>\n",
    "    <td>+3.99</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Average</strong></td>\n",
    "    <td>64.95</td>\n",
    "    <td>60.31</td>\n",
    "    <td>+4.64</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Social Network Metadata Feature Set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------social network metadata----------\n",
      "-----cCON-----\n",
      "NB: train accuracy - 59.06% test accuracy - 59.58%\n",
      "LR: train accuracy - 58.05% test accuracy - 58.53%\n",
      "MLP:train accuracy - 55.78% test accuracy - 55.45%\n",
      "GB: train accuracy - 94.88% test accuracy - 94.62%\n",
      "-----cAGR-----\n",
      "NB: train accuracy - 59.51% test accuracy - 56.57%\n",
      "LR: train accuracy - 57.77% test accuracy - 57.27%\n",
      "MLP:train accuracy - 46.32% test accuracy - 46.29%\n",
      "GB: train accuracy - 97.0% test accuracy - 96.29%\n",
      "-----cNEU-----\n",
      "NB: train accuracy - 53.16% test accuracy - 54.83%\n",
      "LR: train accuracy - 68.97% test accuracy - 67.13%\n",
      "MLP:train accuracy - 62.82% test accuracy - 61.82%\n",
      "GB: train accuracy - 97.79% test accuracy - 97.2%\n",
      "-----cOPN-----\n",
      "NB: train accuracy - 67.48% test accuracy - 65.8%\n",
      "LR: train accuracy - 73.68% test accuracy - 76.15%\n",
      "MLP:train accuracy - 26.0% test accuracy - 23.57%\n",
      "GB: train accuracy - 95.47% test accuracy - 94.97%\n",
      "-----cEXT-----\n",
      "NB: train accuracy - 59.96% test accuracy - 62.24%\n",
      "LR: train accuracy - 63.68% test accuracy - 65.1%\n",
      "MLP:train accuracy - 57.35% test accuracy - 58.32%\n",
      "GB: train accuracy - 97.82% test accuracy - 97.06%\n"
     ]
    }
   ],
   "source": [
    "train_test_label('social network metadata',social_network_metadata, traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Best Results for Social Network Metadata Feature Set compared to Hypothetical Accuracies:</p>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Big-5 Trait</th>\n",
    "    <th>Best Accuracy % (GB)</th>\n",
    "    <th>Hypothetical Accuracy %</th>\n",
    "    <th>Difference %</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Conscientiousness</td>\n",
    "    <td>94.62</td>\n",
    "    <td>54.06</td>\n",
    "    <td>+40.56</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Agreeableness</td>\n",
    "    <td>96.29</td>\n",
    "    <td>53.12</td>\n",
    "    <td>+43.17</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neuroticism</td>\n",
    "    <td>97.2</td>\n",
    "    <td>62.52</td>\n",
    "    <td>+34.68</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Openness</td>\n",
    "    <td>94.97</td>\n",
    "    <td>74.31</td>\n",
    "    <td>+20.66</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Extraversion</td>\n",
    "    <td>97.06</td>\n",
    "    <td>57.55</td>\n",
    "    <td>+39.51</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Average</strong></td>\n",
    "    <td>96.68</td>\n",
    "    <td>60.31</td>\n",
    "    <td>+36.37</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>All features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------all features----------\n",
      "-----cCON-----\n",
      "NB: train accuracy - 59.02% test accuracy - 59.65%\n",
      "LR: train accuracy - 58.4% test accuracy - 58.95%\n",
      "MLP:train accuracy - 54.02% test accuracy - 54.2%\n",
      "GB: train accuracy - 95.29% test accuracy - 95.03%\n",
      "-----cAGR-----\n",
      "NB: train accuracy - 59.23% test accuracy - 56.5%\n",
      "LR: train accuracy - 57.61% test accuracy - 56.92%\n",
      "MLP:train accuracy - 46.71% test accuracy - 46.92%\n",
      "GB: train accuracy - 95.85% test accuracy - 95.38%\n",
      "-----cNEU-----\n",
      "NB: train accuracy - 53.11% test accuracy - 54.76%\n",
      "LR: train accuracy - 69.14% test accuracy - 67.27%\n",
      "MLP:train accuracy - 62.47% test accuracy - 60.77%\n",
      "GB: train accuracy - 97.8% test accuracy - 97.2%\n",
      "-----cOPN-----\n",
      "NB: train accuracy - 66.26% test accuracy - 64.83%\n",
      "LR: train accuracy - 73.68% test accuracy - 76.15%\n",
      "MLP:train accuracy - 26.01% test accuracy - 23.57%\n",
      "GB: train accuracy - 95.43% test accuracy - 95.03%\n",
      "-----cEXT-----\n",
      "NB: train accuracy - 60.03% test accuracy - 62.24%\n",
      "LR: train accuracy - 63.92% test accuracy - 65.38%\n",
      "MLP:train accuracy - 57.35% test accuracy - 58.32%\n",
      "GB: train accuracy - 97.82% test accuracy - 97.06%\n"
     ]
    }
   ],
   "source": [
    "train_test_label('all features',all_features, traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Best Results for All Feature Set compared to Hypothetical Accuracies:</p>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Big-5 Trait</th>\n",
    "    <th>Best Accuracy % (GB)</th>\n",
    "    <th>Hypothetical Accuracy %</th>\n",
    "    <th>Difference %</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Conscientiousness</td>\n",
    "    <td>95.03</td>\n",
    "    <td>54.06</td>\n",
    "    <td>+40.97</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Agreeableness</td>\n",
    "    <td>95.38</td>\n",
    "    <td>53.12</td>\n",
    "    <td>+42.26</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neuroticism</td>\n",
    "    <td>97.2</td>\n",
    "    <td>62.52</td>\n",
    "    <td>+34.68</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Openness</td>\n",
    "    <td>95.03</td>\n",
    "    <td>74.31</td>\n",
    "    <td>+20.72</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Extraversion</td>\n",
    "    <td>97.06</td>\n",
    "    <td>57.55</td>\n",
    "    <td>+39.51</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>Average</strong></td>\n",
    "    <td>95.94</td>\n",
    "    <td>60.31</td>\n",
    "    <td>+35.63</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
